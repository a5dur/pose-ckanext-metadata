name: CKAN Data Pipeline

on:
  workflow_dispatch:
    inputs:
      skip_scripts:
        description: 'Comma-separated list of script numbers to skip (e.g., "2,4")'
        required: false
        default: ''
        type: string
      process_rows:
        description: 'Number of rows to process (leave empty for all)'
        required: false
        default: ''
        type: string
      upload_screenshots:
        description: 'Upload screenshots to CKAN datasets'
        required: false
        default: true
        type: boolean
      screenshot_test_mode:
        description: 'Test mode: only upload first 3 screenshots'
        required: false
        default: false
        type: boolean

env:
  PYTHONUNBUFFERED: 1
  PYTHONIOENCODING: utf-8

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      skip_list: ${{ steps.parse_skip.outputs.skip_list }}
    steps:
      - name: Parse skip list
        id: parse_skip
        run: |
          skip_input="${{ github.event.inputs.skip_scripts }}"
          if [ -n "$skip_input" ]; then
            echo "skip_list=[$skip_input]" >> $GITHUB_OUTPUT
          else
            echo "skip_list=[]" >> $GITHUB_OUTPUT
          fi

  pipeline:
    runs-on: ubuntu-latest
    needs: setup
    continue-on-error: false
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          cd sites-data-fetch
          pip install -r requirements.txt

      - name: Verify initial data file
        run: |
          cd sites-data-fetch
          if [ ! -f "0.csv" ]; then
            echo "Error: 0.csv not found"
            exit 1
          fi
          echo "Initial data file found: 0.csv"
          wc -l 0.csv

      - name: Run Script 1 - Name Processing
        id: script1
        continue-on-error: true
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "1"; then
            echo "Skipping script 1 as requested"
            if [ ! -f "1.csv" ]; then
              echo "Warning: 1.csv doesn't exist and script 1 was skipped"
              cp 0.csv 1.csv
            fi
            exit 0
          fi
          
          echo "Starting Script 1: Name Processing"
          python 1-nameProcess.py
          
          if [ $? -eq 0 ]; then
            echo "Script 1 completed successfully"
            if [ -f "1.csv" ]; then
              echo "Output file created: 1.csv"
              wc -l 1.csv
            else
              echo "Warning: Expected output file 1.csv not found"
            fi
          else
            echo "Script 1 failed with exit code $?"
            # Create fallback file to allow pipeline to continue
            if [ ! -f "1.csv" ]; then
              cp 0.csv 1.csv
              echo "Created fallback 1.csv from 0.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Run Script 2 - CKAN Action API
        id: script2
        continue-on-error: true
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "2"; then
            echo "Skipping script 2 as requested"
            if [ ! -f "2.csv" ]; then
              echo "Warning: 2.csv doesn't exist and script 2 was skipped"
              cp 1.csv 2.csv
            fi
            exit 0
          fi
          
          echo "Starting Script 2: CKAN Action API"
          python 2-CKANActionAPI.py
          
          if [ $? -eq 0 ]; then
            echo "Script 2 completed successfully"
            if [ -f "2.csv" ]; then
              echo "Output file created: 2.csv"
              wc -l 2.csv
            fi
          else
            echo "Script 2 failed with exit code $?"
            if [ ! -f "2.csv" ]; then
              cp 1.csv 2.csv
              echo "Created fallback 2.csv from 1.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Run Script 3 - Site Type Detection
        id: script3
        continue-on-error: true
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "3"; then
            echo "Skipping script 3 as requested"
            if [ ! -f "3.csv" ]; then
              echo "Warning: 3.csv doesn't exist and script 3 was skipped"
              cp 2.csv 3.csv
            fi
            exit 0
          fi
          
          echo "Starting Script 3: Site Type Detection"
          python 3-siteType.py
          
          if [ $? -eq 0 ]; then
            echo "Script 3 completed successfully"
            if [ -f "3.csv" ]; then
              echo "Output file created: 3.csv"
              wc -l 3.csv
            fi
          else
            echo "Script 3 failed with exit code $?"
            if [ ! -f "3.csv" ]; then
              cp 2.csv 3.csv
              echo "Created fallback 3.csv from 2.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Run Script 4 - Description Extraction
        id: script4
        continue-on-error: true
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "4"; then
            echo "Skipping script 4 as requested"
            if [ ! -f "4.csv" ]; then
              echo "Warning: 4.csv doesn't exist and script 4 was skipped"
              cp 3.csv 4.csv
            fi
            exit 0
          fi
          
          echo "Starting Script 4: Description Extraction"
          python 4-description.py
          
          if [ $? -eq 0 ]; then
            echo "Script 4 completed successfully"
            if [ -f "4.csv" ]; then
              echo "Output file created: 4.csv"
              wc -l 4.csv
            fi
          else
            echo "Script 4 failed with exit code $?"
            if [ ! -f "4.csv" ]; then
              cp 3.csv 4.csv
              echo "Created fallback 4.csv from 3.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Run Script 5 - Location Analysis
        id: script5
        continue-on-error: true
        env:
          OPEN_ROUTER_KEY: ${{ secrets.OPEN_ROUTER_KEY }}
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "5"; then
            echo "Skipping script 5 as requested"
            if [ ! -f "5.csv" ]; then
              echo "Warning: 5.csv doesn't exist and script 5 was skipped"
              cp 4.csv 5.csv
            fi
            exit 0
          fi
          
          if [ -z "$OPEN_ROUTER_KEY" ]; then
            echo "Error: OPEN_ROUTER_KEY secret not set, required for script 5"
            cp 4.csv 5.csv
            echo "Created fallback 5.csv from 4.csv due to missing API key"
            exit 1
          fi
          
          echo "Starting Script 5: Location Analysis"
          
          # Modify rows to process if specified
          process_rows="${{ github.event.inputs.process_rows }}"
          if [ -n "$process_rows" ]; then
            echo "Limiting processing to $process_rows rows"
            # This would require modifying the script or using environment variables
            # For now, we'll run as-is since the script has ROWS_TO_PROCESS = None
          fi
          
          python 5-locationAnalyser.py
          
          if [ $? -eq 0 ]; then
            echo "Script 5 completed successfully"
            if [ -f "5.csv" ]; then
              echo "Output file created: 5.csv"
              wc -l 5.csv
            fi
          else
            echo "Script 5 failed with exit code $?"
            if [ ! -f "5.csv" ]; then
              cp 4.csv 5.csv
              echo "Created fallback 5.csv from 4.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Run Script 6 - Geocoding
        id: script6
        continue-on-error: true
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "6"; then
            echo "Skipping script 6 as requested"
            if [ ! -f "6.csv" ]; then
              echo "Warning: 6.csv doesn't exist and script 6 was skipped"
              cp 5.csv 6.csv
            fi
            exit 0
          fi
          
          echo "Starting Script 6: Geocoding"
          python 6-geocode.py
          
          if [ $? -eq 0 ]; then
            echo "Script 6 completed successfully"
            if [ -f "6.csv" ]; then
              echo "Output file created: 6.csv"
              wc -l 6.csv
            fi
          else
            echo "Script 6 failed with exit code $?"
            if [ ! -f "6.csv" ]; then
              cp 5.csv 6.csv
              echo "Created fallback 6.csv from 5.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Run Script 7 - Timestamp
        id: script7
        continue-on-error: true
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "7"; then
            echo "Skipping script 7 as requested"
            if [ ! -f "7.csv" ]; then
              echo "Warning: 7.csv doesn't exist and script 7 was skipped"
              cp 6.csv 7.csv
            fi
            exit 0
          fi
          
          echo "Starting Script 7: Timestamp"
          python 7-tstamp.py
          
          if [ $? -eq 0 ]; then
            echo "Script 7 completed successfully"
            if [ -f "7.csv" ]; then
              echo "Output file created: 7.csv"
              wc -l 7.csv
            fi
          else
            echo "Script 7 failed with exit code $?"
            if [ ! -f "7.csv" ]; then
              cp 6.csv 7.csv
              echo "Created fallback 7.csv from 6.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Upload Screenshots to CKAN
        id: screenshots
        continue-on-error: true
        if: ${{ github.event.inputs.upload_screenshots == 'true' }}
        env:
          CKAN_API_KEY: ${{ secrets.CKAN_API_KEY }}
        run: |
          cd sites-data-fetch
          
          echo "Starting Screenshot Upload to CKAN"
          
          # Check if screenshots directory exists
          if [ ! -d "screenshots" ]; then
            echo "Screenshots directory not found, skipping screenshot upload"
            exit 0
          fi
          
          # Check if we have any PNG files
          png_count=$(find screenshots -name "*.png" | wc -l)
          if [ "$png_count" -eq 0 ]; then
            echo "No PNG files found in screenshots directory"
            exit 0
          fi
          
          echo "Found $png_count screenshot files to upload"
          
          # Check if CKAN API key is available
          if [ -z "$CKAN_API_KEY" ]; then
            echo "Warning: CKAN_API_KEY secret not set, using hardcoded key from script"
          fi
          
          # Determine if we're running in test mode
          test_mode_flag=""
          if [ "${{ github.event.inputs.screenshot_test_mode }}" = "true" ]; then
            echo "Running in test mode (first 3 files only)"
            test_mode_flag="test"
          fi
          
          # Run the screenshot uploader
          python screener.py $test_mode_flag
          
          if [ $? -eq 0 ]; then
            echo "Screenshot upload completed successfully"
          else
            echo "Screenshot upload completed with some failures (check logs)"
            exit 1
          fi

      - name: Generate Pipeline Report
        if: always()
        run: |
          echo "## CKAN Data Pipeline Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Script | Status | Notes |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|--------|-------|" >> $GITHUB_STEP_SUMMARY
          
          cd sites-data-fetch
          
          # Check each script outcome
          scripts=("1-nameProcess" "2-CKANActionAPI" "3-siteType" "4-description" "5-locationAnalyser" "6-geocode" "7-tstamp" "screenshots")
          outcomes=("${{ steps.script1.outcome }}" "${{ steps.script2.outcome }}" "${{ steps.script3.outcome }}" "${{ steps.script4.outcome }}" "${{ steps.script5.outcome }}" "${{ steps.script6.outcome }}" "${{ steps.script7.outcome }}" "${{ steps.screenshots.outcome }}")
          
          for i in "${!scripts[@]}"; do
            if [ $i -eq 7 ]; then
              script_num="📷"
              script_name="Screenshot Upload"
              output_file="screenshots/"
            else
              script_num=$((i + 1))
              script_name="${scripts[$i]}"
              output_file="${script_num}.csv"
            fi
            
            outcome="${outcomes[$i]}"
            
            if [ "$outcome" = "success" ]; then
              status="✅ Success"
            elif [ "$outcome" = "failure" ]; then
              status="❌ Failed"
            elif [ "$outcome" = "skipped" ]; then
              status="⏭️ Skipped"
            else
              status="❓ Unknown"
            fi
            
            if [ $i -eq 7 ]; then
              # Screenshots step
              if [ -d "screenshots" ]; then
                png_count=$(find screenshots -name "*.png" | wc -l)
                notes="Screenshots directory: $png_count PNG files"
              else
                notes="No screenshots directory"
              fi
            elif [ -f "$output_file" ]; then
              row_count=$(tail -n +2 "$output_file" | wc -l)
              notes="Output: $output_file ($row_count rows)"
            else
              notes="No output file"
            fi
            
            echo "| $script_num - $script_name | $status | $notes |" >> $GITHUB_STEP_SUMMARY
          done
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### File Progression" >> $GITHUB_STEP_SUMMARY
          for i in {0..7}; do
            if [ -f "${i}.csv" ]; then
              row_count=$(tail -n +2 "${i}.csv" | wc -l)
              file_size=$(ls -lh "${i}.csv" | awk '{print $5}')
              echo "- ${i}.csv: $row_count rows, $file_size" >> $GITHUB_STEP_SUMMARY
            fi
          done
          
          # Add screenshot summary
          if [ -d "screenshots" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Screenshot Files" >> $GITHUB_STEP_SUMMARY
            find screenshots -name "*.png" -exec ls -lh {} \; | head -10 | while read line; do
              echo "- $(echo $line | awk '{print $9 ": " $5}')" >> $GITHUB_STEP_SUMMARY
            done
            total_screenshots=$(find screenshots -name "*.png" | wc -l)
            if [ "$total_screenshots" -gt 10 ]; then
              echo "- ... and $((total_screenshots - 10)) more files" >> $GITHUB_STEP_SUMMARY
            fi
          fi

      - name: Upload Pipeline Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ckan-pipeline-results
          path: |
            sites-data-fetch/*.csv
            sites-data-fetch/*.log
            sites-data-fetch/screenshots/*.png
          retention-days: 30

      - name: Upload Final Dataset
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: final-dataset
          path: sites-data-fetch/7.csv
          retention-days: 90

      - name: Upload Screenshot Logs
        uses: actions/upload-artifact@v4
        if: always() && steps.screenshots.outcome != 'skipped'
        with:
          name: screenshot-upload-logs
          path: sites-data-fetch/screenshot_upload.log
          retention-days: 30
