name: CKAN Data Pipeline

on:
  workflow_dispatch:
    inputs:
      skip_scripts:
        description: 'Comma-separated list of script numbers to skip (e.g., "2,4")'
        required: false
        default: ''
        type: string
      process_rows:
        description: 'Number of rows to process (leave empty for all)'
        required: false
        default: ''
        type: string
      upload_screenshots:
        description: 'Upload screenshots to CKAN datasets'
        required: false
        default: true
        type: boolean
      screenshot_test_mode:
        description: 'Test mode: only upload first 3 screenshots'
        required: false
        default: false
        type: boolean

env:
  PYTHONUNBUFFERED: 1
  PYTHONIOENCODING: utf-8

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      skip_list: ${{ steps.parse_skip.outputs.skip_list }}
    steps:
      - name: Parse skip list
        id: parse_skip
        run: |
          skip_input="${{ github.event.inputs.skip_scripts }}"
          if [ -n "$skip_input" ]; then
            echo "skip_list=[$skip_input]" >> $GITHUB_OUTPUT
          else
            echo "skip_list=[]" >> $GITHUB_OUTPUT
          fi

  pipeline:
    runs-on: ubuntu-latest
    needs: setup
    continue-on-error: false
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'

      - name: Install dependencies
        run: |
          cd sites-data-fetch
          pip install -r requirements.txt

      - name: Verify initial data file
        run: |
          cd sites-data-fetch
          if [ ! -f "0.csv" ]; then
            echo "Error: 0.csv not found"
            exit 1
          fi
          echo "Initial data file found: 0.csv"
          wc -l 0.csv

      - name: Run Script 1 - Name Processing
        id: script1
        continue-on-error: true
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "1"; then
            echo "Skipping script 1 as requested"
            if [ ! -f "1.csv" ]; then
              echo "Warning: 1.csv doesn't exist and script 1 was skipped"
              cp 0.csv 1.csv
            fi
            exit 0
          fi
          
          echo "Starting Script 1: Name Processing"
          python 1-nameProcess.py
          
          if [ $? -eq 0 ]; then
            echo "Script 1 completed successfully"
            if [ -f "1.csv" ]; then
              echo "Output file created: 1.csv"
              wc -l 1.csv
            else
              echo "Warning: Expected output file 1.csv not found"
            fi
          else
            echo "Script 1 failed with exit code $?"
            # Create fallback file to allow pipeline to continue
            if [ ! -f "1.csv" ]; then
              cp 0.csv 1.csv
              echo "Created fallback 1.csv from 0.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Run Script 2 - CKAN Action API
        id: script2
        continue-on-error: true
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "2"; then
            echo "Skipping script 2 as requested"
            if [ ! -f "2.csv" ]; then
              echo "Warning: 2.csv doesn't exist and script 2 was skipped"
              cp 1.csv 2.csv
            fi
            exit 0
          fi
          
          echo "Starting Script 2: CKAN Action API"
          python 2-CKANActionAPI.py
          
          if [ $? -eq 0 ]; then
            echo "Script 2 completed successfully"
            if [ -f "2.csv" ]; then
              echo "Output file created: 2.csv"
              wc -l 2.csv
            fi
          else
            echo "Script 2 failed with exit code $?"
            if [ ! -f "2.csv" ]; then
              cp 1.csv 2.csv
              echo "Created fallback 2.csv from 1.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Run Script 3 - Site Type Detection
        id: script3
        continue-on-error: true
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "3"; then
            echo "Skipping script 3 as requested"
            if [ ! -f "3.csv" ]; then
              echo "Warning: 3.csv doesn't exist and script 3 was skipped"
              cp 2.csv 3.csv
            fi
            exit 0
          fi
          
          echo "Starting Script 3: Site Type Detection"
          python 3-siteType.py
          
          if [ $? -eq 0 ]; then
            echo "Script 3 completed successfully"
            if [ -f "3.csv" ]; then
              echo "Output file created: 3.csv"
              wc -l 3.csv
            fi
          else
            echo "Script 3 failed with exit code $?"
            if [ ! -f "3.csv" ]; then
              cp 2.csv 3.csv
              echo "Created fallback 3.csv from 2.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Run Script 4 - Description Extraction
        id: script4
        continue-on-error: true
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "4"; then
            echo "Skipping script 4 as requested"
            if [ ! -f "4.csv" ]; then
              echo "Warning: 4.csv doesn't exist and script 4 was skipped"
              cp 3.csv 4.csv
            fi
            exit 0
          fi
          
          echo "Starting Script 4: Description Extraction"
          python 4-description.py
          
          if [ $? -eq 0 ]; then
            echo "Script 4 completed successfully"
            if [ -f "4.csv" ]; then
              echo "Output file created: 4.csv"
              wc -l 4.csv
            fi
          else
            echo "Script 4 failed with exit code $?"
            if [ ! -f "4.csv" ]; then
              cp 3.csv 4.csv
              echo "Created fallback 4.csv from 3.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Run Script 5 - Location Analysis
        id: script5
        continue-on-error: true
        env:
          OPEN_ROUTER_KEY: ${{ secrets.OPEN_ROUTER_KEY }}
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "5"; then
            echo "Skipping script 5 as requested"
            if [ ! -f "5.csv" ]; then
              echo "Warning: 5.csv doesn't exist and script 5 was skipped"
              cp 4.csv 5.csv
            fi
            exit 0
          fi
          
          if [ -z "$OPEN_ROUTER_KEY" ]; then
            echo "Error: OPEN_ROUTER_KEY secret not set, required for script 5"
            cp 4.csv 5.csv
            echo "Created fallback 5.csv from 4.csv due to missing API key"
            exit 1
          fi
          
          echo "Starting Script 5: Location Analysis"
          
          # Modify rows to process if specified
          process_rows="${{ github.event.inputs.process_rows }}"
          if [ -n "$process_rows" ]; then
            echo "Limiting processing to $process_rows rows"
            # This would require modifying the script or using environment variables
            # For now, we'll run as-is since the script has ROWS_TO_PROCESS = None
          fi
          
          python 5-locationAnalyser.py
          
          if [ $? -eq 0 ]; then
            echo "Script 5 completed successfully"
            if [ -f "5.csv" ]; then
              echo "Output file created: 5.csv"
              wc -l 5.csv
            fi
          else
            echo "Script 5 failed with exit code $?"
            if [ ! -f "5.csv" ]; then
              cp 4.csv 5.csv
              echo "Created fallback 5.csv from 4.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Run Script 6 - Geocoding
        id: script6
        continue-on-error: true
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "6"; then
            echo "Skipping script 6 as requested"
            if [ ! -f "6.csv" ]; then
              echo "Warning: 6.csv doesn't exist and script 6 was skipped"
              cp 5.csv 6.csv
            fi
            exit 0
          fi
          
          echo "Starting Script 6: Geocoding"
          python 6-geocode.py
          
          if [ $? -eq 0 ]; then
            echo "Script 6 completed successfully"
            if [ -f "6.csv" ]; then
              echo "Output file created: 6.csv"
              wc -l 6.csv
            fi
          else
            echo "Script 6 failed with exit code $?"
            if [ ! -f "6.csv" ]; then
              cp 5.csv 6.csv
              echo "Created fallback 6.csv from 5.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Run Script 7 - Timestamp
        id: script7
        continue-on-error: true
        run: |
          cd sites-data-fetch
          skip_list='${{ needs.setup.outputs.skip_list }}'
          if echo "$skip_list" | grep -q "7"; then
            echo "Skipping script 7 as requested"
            if [ ! -f "7.csv" ]; then
              echo "Warning: 7.csv doesn't exist and script 7 was skipped"
              cp 6.csv 7.csv
            fi
            exit 0
          fi
          
          echo "Starting Script 7: Timestamp"
          python 7-tstamp.py
          
          if [ $? -eq 0 ]; then
            echo "Script 7 completed successfully"
            if [ -f "7.csv" ]; then
              echo "Output file created: 7.csv"
              wc -l 7.csv
            fi
          else
            echo "Script 7 failed with exit code $?"
            if [ ! -f "7.csv" ]; then
              cp 6.csv 7.csv
              echo "Created fallback 7.csv from 6.csv to continue pipeline"
            fi
            exit 1
          fi

      - name: Install Chrome and Setup for Screenshots
        id: chrome_setup
        if: ${{ github.event.inputs.upload_screenshots == 'true' }}
        run: |
          # Install Chrome
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          
          # Install ChromeDriver
          CHROME_VERSION=$(google-chrome --version | cut -d " " -f3 | cut -d "." -f1)
          wget -O /tmp/chromedriver.zip "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_${CHROME_VERSION}/chromedriver_linux64.zip"
          sudo unzip /tmp/chromedriver.zip -d /usr/local/bin/
          sudo chmod +x /usr/local/bin/chromedriver
          
          # Install additional Python packages for screenshots
          pip install selenium pandas openpyxl

      - name: Take Screenshots of CKAN Portals
        id: screenshots
        continue-on-error: true
        if: ${{ github.event.inputs.upload_screenshots == 'true' }}
        run: |
          cd sites-data-fetch
          
          echo "Starting CKAN Portal Screenshot Process"
          
          # Check if we have the final CSV file (7.csv) to use as input
          if [ ! -f "7.csv" ]; then
            echo "Final CSV file (7.csv) not found, cannot take screenshots"
            exit 1
          fi
          
          # Convert CSV to Excel format that the screenshot script expects
          python -c "
          import pandas as pd
          import sys
          
          try:
              # Read the final CSV
              df = pd.read_csv('7.csv')
              
              # Check if required columns exist (adapt based on your CSV structure)
              if 'url' not in df.columns:
                  # Try to find URL column with different names
                  url_cols = [col for col in df.columns if 'url' in col.lower() or 'site' in col.lower()]
                  if url_cols:
                      df['url'] = df[url_cols[0]]
                  else:
                      print('No URL column found in CSV')
                      sys.exit(1)
              
              if 'name' not in df.columns:
                  # Try to find name column with different names
                  name_cols = [col for col in df.columns if 'name' in col.lower() or 'title' in col.lower()]
                  if name_cols:
                      df['name'] = df[name_cols[0]]
                  else:
                      # Use URL as name if no name column found
                      df['name'] = df['url']
              
              # Save as Excel file for the screenshot script
              df[['name', 'url']].to_excel('output.xlsx', index=False)
              print(f'Created output.xlsx with {len(df)} rows')
              
          except Exception as e:
              print(f'Error preparing data for screenshots: {e}')
              sys.exit(1)
          "
          
          if [ $? -ne 0 ]; then
            echo "Failed to prepare data for screenshots"
            exit 1
          fi
          
          # Modify the screenshot script if we're in test mode
          if [ "${{ github.event.inputs.screenshot_test_mode }}" = "true" ]; then
            echo "Running in test mode - will limit screenshots"
            # Create a modified version that processes only first 5 sites
            python -c "
            import pandas as pd
            df = pd.read_excel('output.xlsx')
            df.head(5).to_excel('output.xlsx', index=False)
            print(f'Limited to first 5 sites for testing')
            "
          fi
          
          # Run the screenshot taker with headless mode for CI
          python -c "
          import sys
          sys.path.append('.')
          
          # Read the screenshot script and modify it for headless mode
          with open('8-snapshotter.py', 'r') as f:
              script_content = f.read()
          
          # Enable headless mode for CI environment
          script_content = script_content.replace('# chrome_options.add_argument(\"--headless\")', 'chrome_options.add_argument(\"--headless\")')
          
          # Write modified script
          with open('8-snapshotter-ci.py', 'w') as f:
              f.write(script_content)
          
          print('Modified screenshot script for CI environment')
          "
          
          # Execute the screenshot script
          python 8-snapshotter-ci.py
          
          if [ $? -eq 0 ]; then
            echo "Screenshot process completed successfully"
            
            # Check results
            if [ -d "screenshots" ]; then
              screenshot_count=$(find screenshots -name "*.png" | wc -l)
              echo "Generated $screenshot_count screenshots"
              
              if [ -f "screenshots/screenshot_report.txt" ]; then
                echo "Screenshot report:"
                cat screenshots/screenshot_report.txt
              fi
            else
              echo "No screenshots directory created"
            fi
          else
            echo "Screenshot process completed with errors (check logs)"
            exit 1
          fi

      - name: Generate Pipeline Report
        if: always()
        run: |
          echo "## CKAN Data Pipeline Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Script | Status | Notes |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|--------|-------|" >> $GITHUB_STEP_SUMMARY
          
          cd sites-data-fetch
          
          # Check each script outcome
          scripts=("1-nameProcess" "2-CKANActionAPI" "3-siteType" "4-description" "5-locationAnalyser" "6-geocode" "7-tstamp" "screenshots" "upload_screenshots")
          outcomes=("${{ steps.script1.outcome }}" "${{ steps.script2.outcome }}" "${{ steps.script3.outcome }}" "${{ steps.script4.outcome }}" "${{ steps.script5.outcome }}" "${{ steps.script6.outcome }}" "${{ steps.script7.outcome }}" "${{ steps.screenshots.outcome }}" "${{ steps.upload_screenshots.outcome }}")
          
          for i in "${!scripts[@]}"; do
            if [ $i -eq 7 ]; then
              script_num="📷"
              script_name="Take Screenshots"
              output_file="screenshots/"
            elif [ $i -eq 8 ]; then
              script_num="📤"
              script_name="Upload Screenshots to CKAN"
              output_file="screenshot_upload.log"
            else
              script_num=$((i + 1))
              script_name="${scripts[$i]}"
              output_file="${script_num}.csv"
            fi
            
            outcome="${outcomes[$i]}"
            
            if [ "$outcome" = "success" ]; then
              status="✅ Success"
            elif [ "$outcome" = "failure" ]; then
              status="❌ Failed"
            elif [ "$outcome" = "skipped" ]; then
              status="⏭️ Skipped"
            else
              status="❓ Unknown"
            fi
            
            if [ $i -eq 7 ]; then
              # Screenshots step
              if [ -d "screenshots" ]; then
                png_count=$(find screenshots -name "*.png" | wc -l)
                notes="Screenshots directory: $png_count PNG files"
              else
                notes="No screenshots directory"
              fi
            elif [ -f "$output_file" ]; then
              row_count=$(tail -n +2 "$output_file" | wc -l)
              notes="Output: $output_file ($row_count rows)"
            else
              notes="No output file"
            fi
            
            echo "| $script_num - $script_name | $status | $notes |" >> $GITHUB_STEP_SUMMARY
          done
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### File Progression" >> $GITHUB_STEP_SUMMARY
          for i in {0..7}; do
            if [ -f "${i}.csv" ]; then
              row_count=$(tail -n +2 "${i}.csv" | wc -l)
              file_size=$(ls -lh "${i}.csv" | awk '{print $5}')
              echo "- ${i}.csv: $row_count rows, $file_size" >> $GITHUB_STEP_SUMMARY
            fi
          done
          
          # Add screenshot summary
          if [ -d "screenshots" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Screenshot Files" >> $GITHUB_STEP_SUMMARY
            find screenshots -name "*.png" -exec ls -lh {} \; | head -10 | while read line; do
              echo "- $(echo $line | awk '{print $9 ": " $5}')" >> $GITHUB_STEP_SUMMARY
            done
            total_screenshots=$(find screenshots -name "*.png" | wc -l)
            if [ "$total_screenshots" -gt 10 ]; then
              echo "- ... and $((total_screenshots - 10)) more files" >> $GITHUB_STEP_SUMMARY
            fi
          fi

      - name: Upload Pipeline Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ckan-pipeline-results
          path: |
            sites-data-fetch/*.csv
            sites-data-fetch/*.log
            sites-data-fetch/screenshots/*.png
          retention-days: 30

      - name: Upload Final Dataset
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: final-dataset
          path: sites-data-fetch/7.csv
          retention-days: 90

      - name: Upload Screenshot Logs
        uses: actions/upload-artifact@v4
        if: always() && steps.screenshots.outcome != 'skipped'
        with:
          name: screenshot-upload-logs
          path: sites-data-fetch/screenshot_upload.log
          retention-days: 30
